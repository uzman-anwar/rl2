{"eval/mean_reward": 2071.7449940051315, "eval/mean_ep_length": 500.0, "eval/best_mean_reward": 2388.505933522344, "rollout/adjusted_reward": 4.6931538581848145, "time/iterations": 489, "time/fps": 1248, "time/time_elapsed": 4011, "time/total_timesteps": 5007360, "infos/reward_run": 5.368933482833995, "infos/reward_ctrl": -0.42845886588096627, "infos/cost": 0.0, "rollout/ep_rew_mean": 2217.95106823, "rollout/ep_len_mean": 500.0, "_step": 5007360, "_runtime": 4041, "_timestamp": 1608183096, "train/learning_rate": 0.0003, "train/entropy_loss": -3.2737991377711295, "train/policy_gradient_loss": 0.001217895053673501, "train/reward_value_loss": 0.052683443628484386, "train/cost_value_loss": 1.4069614949097086e-06, "train/approx_kl": 0.023661937564611435, "train/clip_fraction": 0.27958984375, "train/loss": 0.016911281272768974, "train/reward_explained_variance": 0.9381977021694183, "train/cost_explained_variance": 0.5740714371204376, "train/nu": 6.285252094268799, "train/nu_loss": -0.0, "train/average_cost": 0.0, "train/total_cost": 0.0, "train/std": 0.4238341748714447, "train/n_updates": 4880, "train/clip_range": 0.2}