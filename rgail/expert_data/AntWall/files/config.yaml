wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.10.12
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.8.5
batch_size:
  desc: null
  value: 128
budget:
  desc: null
  value: 0.0
clip_range:
  desc: null
  value: 0.4
clip_range_cost_vf:
  desc: null
  value: null
clip_range_reward_vf:
  desc: null
  value: null
cn_acs_select_dim:
  desc: null
  value: null
cn_device:
  desc: null
  value: null
cn_obs_select_dim:
  desc: null
  value: null
cn_path:
  desc: null
  value: null
cnn_features_dim:
  desc: null
  value: 512
config_file:
  desc: null
  value: null
cost_gae_lambda:
  desc: null
  value: 0.9
cost_gamma:
  desc: null
  value: 0.99
cost_info_str:
  desc: null
  value: cost
cost_vf_coef:
  desc: null
  value: 0.5
cost_vf_layers:
  desc: null
  value:
  - 64
  - 64
device:
  desc: null
  value: cpu
dont_normalize:
  desc: null
  value: false
ent_coef:
  desc: null
  value: 0.0
eval_env_id:
  desc: null
  value: AntWallTest-v0
eval_every:
  desc: null
  value: 2048
file_to_run:
  desc: null
  value: cpg
group:
  desc: null
  value: AntWall
learning_rate:
  desc: null
  value: 3.0e-05
max_grad_norm:
  desc: null
  value: 0.5
n_epochs:
  desc: null
  value: 20
n_steps:
  desc: null
  value: 2048
name:
  desc: null
  value: AntWall-v0_AntWallTest-v0_bs_128_cr_0.4_cgl_0.9_lr_3e-05_ne_20_rgl_0.9_s_37_sid_5
num_threads:
  desc: null
  value: 5
penalty_initial_value:
  desc: null
  value: 1
penalty_learning_rate:
  desc: null
  value: 0.1
plot_every:
  desc: null
  value: 2048
policy_layers:
  desc: null
  value:
  - 64
  - 64
policy_name:
  desc: null
  value: TwoCriticsMlpPolicy
project:
  desc: null
  value: PPO-Debug
reward_gae_lambda:
  desc: null
  value: 0.9
reward_gamma:
  desc: null
  value: 0.99
reward_vf_coef:
  desc: null
  value: 0.5
reward_vf_layers:
  desc: null
  value:
  - 64
  - 64
save_dir:
  desc: null
  value: ./icrl/wandb/run-20210108_164545-alci5o6e/files
save_every:
  desc: null
  value: 100000.0
sde_sample_freq:
  desc: null
  value: -1
seed:
  desc: null
  value: 37
shared_layers:
  desc: null
  value: null
sync_wandb:
  desc: null
  value: false
target_kl:
  desc: null
  value: null
timesteps:
  desc: null
  value: 5000000
train_env_id:
  desc: null
  value: AntWall-v0
update_penalty_after:
  desc: null
  value: 1
use_curiosity_driven_exploration:
  desc: null
  value: false
use_lambda_shaping:
  desc: null
  value: false
use_null_cost:
  desc: null
  value: false
use_pid:
  desc: null
  value: false
use_sde:
  desc: null
  value: false
verbose:
  desc: null
  value: 2
wandb_sweep:
  desc: null
  value: false
